{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21370f10-ef8d-4b6d-a9c4-51ddc15445ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from gensim.models import LsiModel  \n",
    "from gensim.corpora import Dictionary\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    PROCESSED_CORPUS_PICKLE = 'data/paragraph.pkl'\n",
    "    MODEL_SAVE_DIR = 'data/LSI/model/' \n",
    "    TOPIC_RANGE = range(3, 16)\n",
    "    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    print(f\"--- LSI模型训练 ---\")\n",
    "\n",
    "    print(\"--- 正在加载语料库... ---\")\n",
    "    with open(PROCESSED_CORPUS_PICKLE, 'rb') as f:\n",
    "        processed_texts = pickle.load(f)\n",
    "    dictionary = Dictionary(processed_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for n_topics in TOPIC_RANGE:\n",
    "        print(f\"\\n--- 开始训练: {n_topics} 主题 ---\")\n",
    "        \n",
    "        model = LsiModel(\n",
    "            corpus=corpus, \n",
    "            num_topics=n_topics, \n",
    "            id2word=dictionary\n",
    "        )\n",
    "        \n",
    "        model.save(os.path.join(MODEL_SAVE_DIR, f'lsi_model_{n_topics}.model'))\n",
    "        print(f\"--- 已保存: {n_topics} 主题的模型 ---\")\n",
    "\n",
    "    print(f\"\\n 全部模型训练完毕, 总耗时: {time.time() - start_time:.2f} 秒\")\n",
    "    print(f\"模型保存在: {MODEL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03615b35-30bb-4069-8ccd-30e1837d44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import LsiModel, KeyedVectors \n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity, InvertedRBO\n",
    "\n",
    "\n",
    "PROCESSED_CORPUS_PICKLE = 'data/paragraph.pkl'\n",
    "MODEL_SAVE_DIR = 'data/LSI/model/' \n",
    "TENCENT_WV_PATH = 'data/origin/tencent-ailab-embedding-zh-d100-v0.2.0-s.txt' \n",
    "TOPIC_RANGE = range(3, 16)\n",
    "RESULTS_CSV_PATH = 'data/LSI/lsi_evaluation_final.csv' \n",
    "\n",
    "def evaluate_models_focused(model_dir, topic_range, processed_texts, dictionary, word_vectors):\n",
    "    print(\"\\n--- 3. 开始进行专注化评估 ---\")\n",
    "    results = []\n",
    "    \n",
    "\n",
    "    diversity_metric = TopicDiversity(topk=10)\n",
    "    rbo_metric = InvertedRBO(topk=10, weight=0.9)\n",
    "\n",
    "    for n_topics in topic_range:\n",
    "        model_path = os.path.join(model_dir, f'lsi_model_{n_topics}.model')\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"警告: 模型文件未找到，跳过: {model_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"--- 正在评估: {n_topics} 主题的模型 ---\")\n",
    "\n",
    "        lsi_model = LsiModel.load(model_path)\n",
    "        \n",
    "        topics_for_coherence = [[word for word, _ in lsi_model.show_topic(i, topn=20)] for i in range(n_topics)]\n",
    "        topics_for_diversity = [[word for word, _ in lsi_model.show_topic(i, topn=10)] for i in range(n_topics)]\n",
    "        \n",
    "        coherence_model = CoherenceModel(\n",
    "            topics=topics_for_coherence,\n",
    "            texts=processed_texts,\n",
    "            dictionary=dictionary,\n",
    "            coherence='c_w2v',\n",
    "            keyed_vectors=word_vectors\n",
    "        )\n",
    "        cw2v_semantic = coherence_model.get_coherence()\n",
    "\n",
    "        model_output_for_diversity = {\"topics\": topics_for_diversity}\n",
    "        diversity = diversity_metric.score(model_output_for_diversity)\n",
    "        rbo = rbo_metric.score(model_output_for_diversity)\n",
    "\n",
    "        print(f\"    - C_W2V (Semantic, topk=20): {cw2v_semantic:.4f}\")\n",
    "        print(f\"    - Topic Diversity (topk=10): {diversity:.4f}\")\n",
    "        print(f\"    - InvertedRBO (topk=10): {rbo:.4f}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"num_topics\": n_topics,\n",
    "            \"C_W2V (Semantic)\": cw2v_semantic,\n",
    "            \"Topic Diversity\": diversity,\n",
    "            \"InvertedRBO\": rbo\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results).set_index(\"num_topics\")\n",
    "\n",
    "def plot_results(results_df):\n",
    "    print(\"\\n--- 4. 正在可视化评估结果... ---\")\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    ax1.set_xlabel('Number of Topics')\n",
    "    ax1.set_ylabel('C_W2V Semantic Coherence (topk=20)', color='tab:red')\n",
    "    ax1.plot(results_df.index, results_df['C_W2V (Semantic)'], color='tab:red', marker='o', linewidth=2.5, label='C_W2V (Semantic)')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "    ax1.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Diversity Scores (topk=10)', color='tab:blue')\n",
    "    ax2.plot(results_df.index, results_df['Topic Diversity'], color='tab:blue', marker='x', linestyle='-', label='Topic Diversity')\n",
    "    ax2.plot(results_df.index, results_df['InvertedRBO'], color='tab:cyan', marker='x', linestyle='--', label='InvertedRBO')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 0.96), ncol=3, fontsize='medium')\n",
    "    fig.suptitle('专注化LSI模型评估: 语义一致性 vs. 多样性', fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.92])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"--- 1. 正在加载本地语料库... ---\")\n",
    "    with open(PROCESSED_CORPUS_PICKLE, 'rb') as f:\n",
    "        processed_texts = pickle.load(f)\n",
    "    dictionary = Dictionary(processed_texts)\n",
    "    \n",
    "    print(f\"\\n--- 2. 正在加载腾讯中文词向量模型 (首次加载可能需要较长时间)... ---\")\n",
    "    if not os.path.exists(TENCENT_WV_PATH):\n",
    "        raise FileNotFoundError(f\"错误: 腾讯词向量文件未找到，请检查路径: {TENCENT_WV_PATH}\")\n",
    "    \n",
    "    word_vectors = KeyedVectors.load_word2vec_format(TENCENT_WV_PATH, binary=False)\n",
    "    \n",
    "    print(\"--- 词向量模型加载成功 ---\")\n",
    "\n",
    "    results_df = evaluate_models_focused(MODEL_SAVE_DIR, TOPIC_RANGE, processed_texts, dictionary, word_vectors)\n",
    "    \n",
    "    if not results_df.empty:\n",
    "        print(\"\\n--- 最终评估完成, 结果如下: ---\")\n",
    "        print(results_df)\n",
    "        results_df.to_csv(RESULTS_CSV_PATH)\n",
    "        print(f\"\\n评估结果已保存到 {RESULTS_CSV_PATH}\")\n",
    "        plot_results(results_df)\n",
    "    else:\n",
    "        print(\"\\n--- 未找到任何模型进行评估 ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
