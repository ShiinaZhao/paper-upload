{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3bfe6-3da9-4ceb-9247-43e2db037e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random \n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import bitermplus as btm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    PROCESSED_CORPUS_PICKLE = 'data/paragraph.pkl'\n",
    "    MODEL_SAVE_DIR = 'data/BTM/model/'\n",
    "    TOPIC_RANGE = range(3, 16)\n",
    "    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    \n",
    "    FILTER_NO_BELOW = 50     \n",
    "    FILTER_NO_ABOVE = 0.6   \n",
    "    FILTER_KEEP_N = 4000   \n",
    "\n",
    "    BITERM_WINDOW_SIZE = 4    \n",
    "\n",
    "    SAMPLING_RATE = 0.6     \n",
    "\n",
    "    print(\"--- 正在加载语料库... ---\")\n",
    "    with open(PROCESSED_CORPUS_PICKLE, 'rb') as f:\n",
    "        processed_texts = pickle.load(f)\n",
    "\n",
    "    original_count = len(processed_texts)\n",
    "    sample_size = int(original_count * SAMPLING_RATE)\n",
    "    print(f\"--- [终极手段] 已启用数据抽样，将从 {original_count} 条数据中随机抽取 {sample_size} 条 ---\")\n",
    "    processed_texts = random.sample(processed_texts, sample_size)\n",
    "    print(f\"--- 语料库加载完成，将处理 {len(processed_texts)} 篇文档。---\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- 正在使用Gensim在抽样后的数据上构建和过滤词典... ---\")\n",
    "    \n",
    "    dictionary = Dictionary(processed_texts)\n",
    "    print(f\"    - 抽样后语料的原始词汇表大小: {len(dictionary)}\")\n",
    "\n",
    "    dictionary.filter_extremes(\n",
    "        no_below=FILTER_NO_BELOW, \n",
    "        no_above=FILTER_NO_ABOVE, \n",
    "        keep_n=FILTER_KEEP_N\n",
    "    )\n",
    "    dictionary.compactify()\n",
    "    \n",
    "    vocab = list(dictionary.token2id.keys())\n",
    "    print(f\"    - 【终极过滤后】词汇表大小: {len(vocab)}\")\n",
    "\n",
    "    print(\"--- 使用过滤后的词汇表进行最终向量化... ---\")\n",
    "    texts_str = [\" \".join(doc) for doc in processed_texts]\n",
    "    del processed_texts\n",
    "\n",
    "    vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "    X = vectorizer.fit_transform(texts_str)\n",
    "    print(f\"    - 生成的词频矩阵 X 的维度: {X.shape}\")\n",
    "\n",
    "    print(\"\\n--- 正在将文本转换为词ID序列 (for biterm generation)... ---\")\n",
    "    texts_vec = btm.get_vectorized_docs(texts_str, np.array(vocab))\n",
    "    del texts_str\n",
    "\n",
    "    print(f\"--- 正在生成 Biterms (滑动窗口大小 = {BITERM_WINDOW_SIZE})... ---\")\n",
    "    biterms = btm.get_biterms(texts_vec, win=BITERM_WINDOW_SIZE)\n",
    "    del texts_vec\n",
    "    print(f\"--- Biterms 生成完毕，共计 {len(biterms)} 个。---\")\n",
    "\n",
    "\n",
    "    print(f\"\\n即将开始训练 {len(TOPIC_RANGE)} 个模型...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for n_topics in TOPIC_RANGE:\n",
    "        print(f\"\\n--- 开始训练: {n_topics} 主题 ---\")\n",
    "        model = btm.BTM(\n",
    "            X, np.array(vocab), T=n_topics, M=20, alpha=50/n_topics, beta=0.01\n",
    "        )\n",
    "        model.fit(biterms, iterations=100)\n",
    "        \n",
    "        model_path = os.path.join(MODEL_SAVE_DIR, f'btm_model_{n_topics}.pkl')\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"--- 已保存: {n_topics} 主题的模型到 {model_path} ---\")\n",
    "\n",
    "    print(f\"\\n--- 全部模型训练完毕, 总耗时: {time.time() - start_time:.2f} 秒 ---\")\n",
    "    print(f\"--- 所有模型已保存在目录: {MODEL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2356f2-1fa7-48a2-a707-e5848c01b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity, InvertedRBO\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "PROCESSED_CORPUS_PICKLE = 'data/paragraph.pkl'\n",
    "MODEL_SAVE_DIR = 'data/BTM/model/'\n",
    "TENCENT_WV_PATH = 'data/origin/tencent-ailab-embedding-zh-d100-v0.2.0-s.txt'\n",
    "TOPIC_RANGE = range(3, 16)\n",
    "RESULTS_CSV_PATH = 'data/BTM/btm_evaluation_final.csv'\n",
    "\n",
    "\n",
    "def get_btm_topics(btm_model, topn=20):\n",
    "    \"\"\"\n",
    "    从已加载的 bitermplus BTM 模型对象中提取主题词。\n",
    "    此版本基于诊断脚本的结果，解决了所有已知的 AttributeError 问题。\n",
    "    \"\"\"\n",
    "\n",
    "    if not hasattr(btm_model, 'matrix_topics_words_') and not hasattr(btm_model, 'topics_'):\n",
    "        print(f\"    - 注意: 正在生成主题-词分布矩阵...\")\n",
    "\n",
    "        vocab_size = len(btm_model.vocabulary_)\n",
    "        dummy_X = csr_matrix(([1], ([0], [0])), shape=(1, vocab_size))\n",
    "        btm_model.transform(dummy_X)\n",
    "\n",
    "    if hasattr(btm_model, 'matrix_topics_words_'):\n",
    "        topic_word_dist = btm_model.matrix_topics_words_\n",
    "    elif hasattr(btm_model, 'topics_'):\n",
    "        topic_word_dist = btm_model.topics_\n",
    "    else:\n",
    "        raise AttributeError(\"模型在调用 transform() 后未能生成 'matrix_topics_words_' 或 'topics_' 属性。\")\n",
    "\n",
    "\n",
    "    vocab = btm_model.vocabulary_\n",
    "\n",
    "    topics = []\n",
    "    for topic_dist in topic_word_dist:\n",
    "        top_word_indices = np.argsort(np.asarray(topic_dist))[-topn:][::-1]\n",
    "        topic_words = [vocab[i] for i in top_word_indices]\n",
    "        topics.append(topic_words)\n",
    "    return topics\n",
    "\n",
    "def evaluate_btm_models_focused(model_dir, topic_range, full_processed_texts, full_dictionary, word_vectors):\n",
    "    print(\"\\n--- 3. 开始进行BTM模型评估 ---\")\n",
    "    results = []\n",
    "    diversity_metric = TopicDiversity(topk=10); rbo_metric = InvertedRBO(topk=10, weight=0.9)\n",
    "    for n_topics in topic_range:\n",
    "        model_path = os.path.join(model_dir, f'btm_model_{n_topics}.pkl')\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"警告: 模型文件未找到，跳过: {model_path}\"); continue\n",
    "        print(f\"--- 正在评估: {n_topics} 主题的模型 ---\")\n",
    "        with open(model_path, 'rb') as f:\n",
    "            btm_model = pickle.load(f)\n",
    "        topics_for_coherence = get_btm_topics(btm_model, topn=20)\n",
    "        topics_for_diversity = get_btm_topics(btm_model, topn=10)\n",
    "        coherence_model = CoherenceModel(topics=topics_for_coherence, texts=full_processed_texts, dictionary=full_dictionary, coherence='c_w2v', keyed_vectors=word_vectors)\n",
    "        cw2v_semantic = coherence_model.get_coherence()\n",
    "        model_output_for_diversity = {\"topics\": topics_for_diversity}\n",
    "        diversity = diversity_metric.score(model_output_for_diversity)\n",
    "        rbo = rbo_metric.score(model_output_for_diversity)\n",
    "        print(f\"    - C_W2V (Semantic, topk=20): {cw2v_semantic:.4f}\")\n",
    "        print(f\"    - Topic Diversity (topk=10): {diversity:.4f}\")\n",
    "        print(f\"    - InvertedRBO (topk=10): {rbo:.4f}\")\n",
    "        results.append({\"num_topics\": n_topics, \"C_W2V (Semantic)\": cw2v_semantic, \"Topic Diversity\": diversity, \"InvertedRBO\": rbo})\n",
    "    return pd.DataFrame(results).set_index(\"num_topics\")\n",
    "\n",
    "\n",
    "def plot_results(results_df):\n",
    "    print(\"\\n--- 4. 正在可视化评估结果... ---\")\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 8)); ax1.set_xlabel('Number of Topics'); ax1.set_ylabel('C_W2V Semantic Coherence (topk=20)', color='tab:red')\n",
    "    ax1.plot(results_df.index, results_df['C_W2V (Semantic)'], color='tab:red', marker='o', linewidth=2.5, label='C_W2V (Semantic)')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red'); ax1.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    ax2 = ax1.twinx(); ax2.set_ylabel('Diversity Scores (topk=10)', color='tab:blue')\n",
    "    ax2.plot(results_df.index, results_df['Topic Diversity'], color='tab:blue', marker='x', linestyle='-', label='Topic Diversity')\n",
    "    ax2.plot(results_df.index, results_df['InvertedRBO'], color='tab:cyan', marker='x', linestyle='--', label='InvertedRBO')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue'); fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 0.96), ncol=3, fontsize='medium')\n",
    "    fig.suptitle('BTM 模型评估: 语义一致性 vs. 多样性', fontsize=16); fig.tight_layout(rect=[0, 0.03, 1, 0.92]); plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"--- 1. 正在加载【完整】语料库和词向量... ---\")\n",
    "    with open(PROCESSED_CORPUS_PICKLE, 'rb') as f:\n",
    "        full_processed_texts = pickle.load(f)\n",
    "    if not os.path.exists(TENCENT_WV_PATH):\n",
    "        raise FileNotFoundError(f\"错误: 腾讯词向量文件未找到，请检查路径: {TENCENT_WV_PATH}\")\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(TENCENT_WV_PATH, binary=False)\n",
    "    full_dictionary = Dictionary(full_processed_texts)\n",
    "    print(\"--- 完整语料库和词向量加载成功 ---\")\n",
    "    results_df = evaluate_btm_models_focused(model_dir=MODEL_SAVE_DIR, topic_range=TOPIC_RANGE, full_processed_texts=full_processed_texts, full_dictionary=full_dictionary, word_vectors=word_vectors)\n",
    "    if not results_df.empty:\n",
    "        print(\"\\n--- 最终评估完成, 结果如下: ---\"); print(results_df)\n",
    "        os.makedirs(os.path.dirname(RESULTS_CSV_PATH), exist_ok=True)\n",
    "        results_df.to_csv(RESULTS_CSV_PATH)\n",
    "        print(f\"\\n评估结果已保存到 {RESULTS_CSV_PATH}\"); plot_results(results_df)\n",
    "    else:\n",
    "        print(\"\\n--- 未找到任何模型进行评估 ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
